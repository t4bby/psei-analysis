{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Numerical Python\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\" # Use plotly as the plotting backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "gdp_df = pd.read_csv('inflation.csv')\n",
    "gdp_df['Date'] = pd.to_datetime(gdp_df['Date'])\n",
    "gdp_df['Date'] = gdp_df['Date'].map(dt.datetime.toordinal)\n",
    "# Revert back\n",
    "# gdp_df.index = gdp_df.index.map(dt.datetime.fromordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(gdp_df['Inflation'])\n",
    "features = gdp_df.drop('Inflation', axis = 1)\n",
    "feature_list = list(gdp_df.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = test_features[:, feature_list.index('Date')]\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - test_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Use datetime for creating date objects for plotting\n",
    "import datetime\n",
    "# Dates of training values\n",
    "\n",
    "dates = [datetime.datetime.fromordinal(date) for date in features[:, feature_list.index(\"Date\")]]\n",
    "# Dataframe with true values and dates\n",
    "true_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n",
    "\n",
    "test_dates = [datetime.datetime.fromordinal(date) for date in features[:, feature_list.index(\"Date\")]]\n",
    "\n",
    "# Dataframe with predictions and dates\n",
    "predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions})\n",
    "\n",
    "true_data.set_index('date', inplace=True)\n",
    "true_data.sort_index(inplace=True)\n",
    "\n",
    "predictions_data.set_index('date', inplace=True)\n",
    "predictions_data.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "true_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "predictions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(true_data, predictions_data, left_index=True, right_index=True)\n",
    "df.plot(title='Inflation Predictions', x=['actual', 'prediction'], y='date', labels={'value':'Inflation Rate', 'index':'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df[\"prediction\"] = df[\"prediction\"].round(2)\n",
    "df['Prediction Signal'] = np.where(df['actual'].diff()>0, \"UP\", \"DOWN\")\n",
    "df.to_csv('inflation_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Significance Testing\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "actual = df[\"actual\"]\n",
    "prediction = df[\"prediction\"]\n",
    "\n",
    "#mean\n",
    "actual_mean, prediction_mean = actual.mean(), prediction.mean()\n",
    "\n",
    "#standard deviation\n",
    "actual_sd, prediction_sd = actual.std(ddof=1), prediction.std(ddof=1)\n",
    "\n",
    "#standard error\n",
    "actual_n, prediction_n = len(actual), len(prediction)\n",
    "actual_se, prediction_se = actual_sd/math.sqrt(actual_n), prediction_sd/math.sqrt(prediction_n)\n",
    "\n",
    "#standard error on the difference between men and women\n",
    "se_diff = math.sqrt(actual_se**2.0 + prediction_se**2.0)\n",
    "\n",
    "#t-stat\n",
    "t_stat = (actual_mean - prediction_mean) / se_diff\n",
    "\n",
    "#degrees of freedom\n",
    "degrees_freedom = (actual_sd**2/actual_n + prediction_sd**2/prediction_n)**2 / (actual_sd**4/actual_n**2/(actual_n-1) + prediction_sd**4/prediction_n**2/(prediction_n-1))\n",
    "\n",
    "#critical value\n",
    "alpha = 0.05\n",
    "cv = stats.t.ppf(1.0 - alpha, degrees_freedom)\n",
    "\n",
    "# p-value\n",
    "p = (1 - stats.t.cdf(abs(t_stat), degrees_freedom)) * 2\n",
    "print(\"ttest:\", t_stat, \"critical value:\", cv, \"p-value:\", p)\n",
    "print(\"actual mean:\", actual_mean, \"prediction mean:\", prediction_mean)\n",
    "print(\"actual sd:\", actual_sd, \"prediction sd:\", prediction_sd)\n",
    "print(\"actual se:\", actual_se, \"prediction se:\", prediction_se)\n",
    "print(\"actual n:\", actual_n, \"prediction n:\", prediction_n)\n",
    "print(\"se on diff:\", se_diff)\n",
    "print(\"degrees of freedom:\", round(degrees_freedom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
